{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Multilayer Perceptron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "tr_features = pd.read_csv(\"../data/train_features.csv\")\n",
    "tr_labels = pd.read_csv(\"../data/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "![neuralnet](../references/hidden_layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print(\"BEST PARAMS: {}\\n\".format(results.best_params_))\n",
    "    means = results.cv_results_[\"mean_test_score\"]\n",
    "    stds = results.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_[\"params\"]):\n",
    "        print(\"{} (+/-{}) for {}\".format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['logistic', 'tanh', 'relu'],\n",
       "                         'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
       "                         'learning_rate': ['constant', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [1000]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "parameters = {\n",
    "    \"hidden_layer_sizes\": [(10,), (50,), (100,)],\n",
    "    \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"max_iter\": [1_000],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(mlp, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "\n",
      "0.815 (+/-0.109) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.8 (+/-0.108) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.8 (+/-0.106) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.798 (+/-0.107) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.794 (+/-0.095) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.79 (+/-0.112) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.792 (+/-0.107) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.792 (+/-0.117) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.8 (+/-0.119) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.809 (+/-0.109) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.792 (+/-0.096) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.785 (+/-0.139) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.809 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.807 (+/-0.102) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.803 (+/-0.071) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.794 (+/-0.078) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.798 (+/-0.09) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.809 (+/-0.087) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.796 (+/-0.12) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.779 (+/-0.116) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.781 (+/-0.074) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.796 (+/-0.114) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.8 (+/-0.103) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.79 (+/-0.08) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "0.794 (+/-0.127) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
      "0.794 (+/-0.092) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 1000}\n",
      "0.807 (+/-0.129) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
      "MLPClassifier(activation='logistic', hidden_layer_sizes=(10,), max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "print_results(cv)\n",
    "print(cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/MLP_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, \"../models/MLP_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
